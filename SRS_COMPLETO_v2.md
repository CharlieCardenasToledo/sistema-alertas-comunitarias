# SRS â€“ EspecificaciÃ³n de Requisitos de Software (IEEE 830)
## Sistema de Alertas Comunitarias Verificadas - VERSIÃ“N COMPLETA

## 0. Control del documento
- **Proyecto:** Sistema de Alertas Comunitarias Verificadas (SACV)
- **VersiÃ³n:** 2.0 - Completa con Stack TecnolÃ³gico y Arquitectura
- **Fecha:** 09-ene-2026
- **Autor:** Equipo SACV
- **Asignatura:** Arquitectura e IntegraciÃ³n de Plataformas de TI
- **InstituciÃ³n:** UIDE

---

## 1. IntroducciÃ³n

### 1.1 PropÃ³sito
Este documento especifica de forma completa los requisitos funcionales y no funcionales del **Sistema de Alertas Comunitarias Verificadas (SACV)**, una plataforma que **detecta eventos** (sismos/lluvias/cortes programados) mediante **scraping de fuentes oficiales**, **normaliza** la informaciÃ³n, calcula un **nivel de confianza** por verificaciÃ³n de evidencia y **publica/notifica** alertas a usuarios y administradores.

El documento estÃ¡ dirigido a: docentes evaluadores, equipo de desarrollo, testers y cualquier stakeholder institucional o comunitario.

### 1.2 Alcance
El SACV provee:
- **Ingesta** periÃ³dica (scraping) desde pÃ¡ginas oficiales.
- **NormalizaciÃ³n** de eventos a un esquema comÃºn.
- **VerificaciÃ³n** mediante reglas (lista blanca de dominios, vigencia temporal, deduplicaciÃ³n, corroboraciÃ³n cruzada opcional).
- **PublicaciÃ³n** de alertas en una API y panel web.
- **Notificaciones** (MVP: Telegram/email; opcional: WhatsApp Business Platform en fase final).
- **AuditorÃ­a** (quiÃ©n/quÃ©/cuÃ¡ndo) y observabilidad (logs/mÃ©tricas).

Fuera de alcance (v1):
- App mÃ³vil nativa.
- IntegraciÃ³n oficial por API con redes sociales como fuente primaria.
- Reconocimiento OCR de capturas/imÃ¡genes de rumores.
- AnalÃ­tica avanzada con ML (se reemplaza por reglas explicables).

### 1.3 Definiciones, acrÃ³nimos y abreviaturas
- **SACV:** Sistema de Alertas Comunitarias Verificadas.
- **Scraping:** extracciÃ³n automatizada de informaciÃ³n desde pÃ¡ginas web.
- **Evento:** registro normalizado de sismo/lluvia/corte.
- **Evidencia:** enlace oficial y/o contenido verificable del evento.
- **Score de confianza:** puntuaciÃ³n que determina el estado (Confirmado/En verificaciÃ³n/No verificado).
- **Allowlist/Lista blanca:** dominios/fuentes permitidos como oficiales.
- **DeduplicaciÃ³n:** detecciÃ³n de eventos repetidos.
- **MVP:** Producto mÃ­nimo viable.
- **EDA:** Event-Driven Architecture (Arquitectura orientada a eventos).
- **CQRS:** Command Query Responsibility Segregation.

### 1.4 Referencias
- IEEE 830 â€“ Recommended Practice for Software Requirements Specifications (SRS).
- C4 Model for Software Architecture Documentation.
- PolÃ­ticas internas de seguridad y uso responsable de datos (si aplica).

### 1.5 VisiÃ³n general del documento
- SecciÃ³n 2 describe el producto y su contexto.
- SecciÃ³n 3 detalla requisitos especÃ­ficos (funcionales, datos, interfaces, NFR).
- Secciones 4-7 incluyen casos de uso, criterios de aceptaciÃ³n y trazabilidad.
- **SecciÃ³n 8** especifica el **stack tecnolÃ³gico completo** (100% free/open-source).
- **SecciÃ³n 9** presenta la **arquitectura del sistema** con diagramas.
- **SecciÃ³n 10** define la **estrategia de despliegue** con Docker Compose.
- **SecciÃ³n 11** incluye el **roadmap de desarrollo** por fases.

---

## 2. DescripciÃ³n general

### 2.1 Perspectiva del producto
El SACV es un sistema web con arquitectura orientada a servicios/microservicios. Sus componentes principales:
- **Scrapers por fuente** (workers) â†’ detectan eventos.
- **Normalizador** â†’ estandariza datos.
- **Verificador** â†’ calcula confianza y estado.
- **API de Alertas** â†’ consulta y publicaciÃ³n.
- **Servicio de Notificaciones** â†’ envÃ­os.
- **Panel Web** â†’ monitoreo y administraciÃ³n.

### 2.2 Funciones del producto (alto nivel)
1. Configurar fuentes oficiales y parÃ¡metros de scraping.
2. Ejecutar scraping automÃ¡tico y manual.
3. Transformar eventos a esquema comÃºn.
4. Calcular nivel de confianza (reglas + corroboraciÃ³n opcional).
5. Publicar alertas y exponerlas vÃ­a API.
6. Notificar a usuarios suscritos por canales.
7. Proveer historial, filtros, exportaciÃ³n y auditorÃ­a.

### 2.3 CaracterÃ­sticas de los usuarios
- **Administrador del sistema:** configura fuentes, reglas, usuarios, canales.
- **Operador/Moderador:** revisa alertas en verificaciÃ³n, aprueba/rechaza si se habilita revisiÃ³n humana.
- **Usuario final (comunidad):** consulta alertas, se suscribe a categorÃ­as/zonas, recibe notificaciones.
- **Docente evaluador:** revisa documentaciÃ³n, arquitectura, evidencias y demo.

### 2.4 Restricciones
- Respeto a tÃ©rminos de uso y buenas prÃ¡cticas de scraping (rate limit, no saturaciÃ³n).
- Limitaciones de disponibilidad de fuentes externas.
- Para WhatsApp oficial: requerimientos de configuraciÃ³n/aprobaciÃ³n y polÃ­ticas del proveedor.
- Cumplimiento bÃ¡sico de seguridad: protecciÃ³n de credenciales, HTTPS, control de acceso.
- **RestricciÃ³n presupuestaria:** Uso exclusivo de tecnologÃ­as gratuitas y open-source.

### 2.5 Suposiciones y dependencias
- Las fuentes oficiales publican informaciÃ³n accesible vÃ­a web.
- El sistema tendrÃ¡ conectividad a Internet.
- La infraestructura soportarÃ¡ contenedores (Docker).
- Disponibilidad de servicios gratuitos para notificaciones (Telegram Bot API, SMTP gratuito).

---

## 3. Requisitos especÃ­ficos

### 3.1 Requisitos funcionales (RF)

#### 3.1.1 GestiÃ³n de fuentes
- **RF-01:** El sistema permitirÃ¡ registrar una **fuente oficial** con: nombre, URL base, tipo de evento (sismo/lluvia/corte), dominio, mÃ©todo de extracciÃ³n (CSS/XPath/regex), frecuencia de consulta y estado (activo/inactivo).
- **RF-02:** El sistema permitirÃ¡ mantener una **lista blanca de dominios** permitidos por tipo de evento.
- **RF-03:** El sistema permitirÃ¡ ejecutar un **scraping manual** por fuente desde el panel.

#### 3.1.2 Scraping e ingesta
- **RF-04:** Los scrapers ejecutarÃ¡n consultas periÃ³dicas segÃºn la frecuencia configurada.
- **RF-05:** El sistema almacenarÃ¡ el **evento crudo** (raw) con timestamp de captura y referencia de fuente.
- **RF-06:** El sistema aplicarÃ¡ **control de tasa** (rate limit) y reintentos con backoff ante fallos temporales.
- **RF-07:** El sistema detectarÃ¡ y registrarÃ¡ cambios de estructura (parsing fallido) para revisiÃ³n.

#### 3.1.3 NormalizaciÃ³n
- **RF-08:** El sistema convertirÃ¡ eventos crudos a un **esquema normalizado** comÃºn.
- **RF-09:** El sistema validarÃ¡ campos obligatorios (tipo, fecha/hora, ubicaciÃ³n/zona, descripciÃ³n mÃ­nima, URL evidencia).
- **RF-10:** El sistema generarÃ¡ un **hash de deduplicaciÃ³n** para identificar eventos repetidos.

#### 3.1.4 VerificaciÃ³n y scoring
- **RF-11:** El sistema calcularÃ¡ un **score de confianza** basado en reglas (ver 3.2.3).
- **RF-12:** El sistema clasificarÃ¡ eventos en estados:
  - **CONFIRMADO** (publicable + notifica)
  - **EN_VERIFICACION** (visible en panel; notificaciÃ³n configurable)
  - **NO_VERIFICADO** (no se notifica; visible solo para admin)
- **RF-13:** El sistema implementarÃ¡ **deduplicaciÃ³n**: si un evento equivalente ya existe, se actualiza el historial en vez de crear un duplicado (configurable).
- **RF-14 (Opcional):** CorroboraciÃ³n cruzada: si un evento coincide con otra fuente oficial dentro de una ventana temporal, aumenta el score.

#### 3.1.5 PublicaciÃ³n y consulta
- **RF-15:** El sistema publicarÃ¡ eventos confirmados y permitirÃ¡ consultarlos vÃ­a API REST.
- **RF-16:** El panel permitirÃ¡ filtrar por: tipo, fecha, zona, estado, fuente, severidad.
- **RF-17:** El sistema permitirÃ¡ ver el **detalle** del evento con evidencia (URL) y trazabilidad.
- **RF-18:** El sistema permitirÃ¡ exportar listados en CSV.

#### 3.1.6 Suscripciones y notificaciones
- **RF-19:** El usuario podrÃ¡ suscribirse por tipo de evento y zona.
- **RF-20:** El sistema enviarÃ¡ notificaciones por canal configurado cuando un evento pase a CONFIRMADO.
- **RF-21 (MVP):** Soportar al menos 1 canal: **Telegram** o **Email**.
- **RF-22 (Fase III opcional):** Soportar **WhatsApp** mediante proveedor oficial.

#### 3.1.7 Seguridad y administraciÃ³n
- **RF-23:** El sistema soportarÃ¡ autenticaciÃ³n y roles (Admin, Operador, Usuario).
- **RF-24:** El sistema registrarÃ¡ auditorÃ­a de acciones administrativas (alta/ediciÃ³n de fuentes, cambios de reglas, gestiÃ³n de usuarios).

#### 3.1.8 Observabilidad
- **RF-25:** El sistema registrarÃ¡ logs estructurados por servicio (requestId, eventoId, fuente, estado).
- **RF-26:** El sistema expondrÃ¡ mÃ©tricas mÃ­nimas (eventos detectados, confirmados, fallos de scraping, latencia de pipeline).

---

### 3.2 Modelo de datos

#### 3.2.1 Entidades principales
- **Source**(source_id, name, base_url, type, domain, parser_config, frequency_sec, active, created_at)
- **RawEvent**(raw_id, source_id, fetched_at, raw_payload, raw_hash)
- **Event**(event_id, type, occurred_at, zone, severity, title, description, evidence_url, source_id, dedup_hash, status, score, created_at, updated_at)
- **VerificationRule**(rule_id, name, weight, enabled)
- **Subscription**(sub_id, user_id, type, zone, channel, active)
- **Notification**(notif_id, event_id, channel, to, sent_at, status)
- **AuditLog**(audit_id, user_id, action, entity, entity_id, timestamp, metadata)

#### 3.2.2 Estados
- Event.status âˆˆ {CONFIRMADO, EN_VERIFICACION, NO_VERIFICADO}

#### 3.2.3 Reglas de scoring (ejemplo base)
> Ajustable por el docente/equipo.
- **R1 Dominio en lista blanca**: +40
- **R2 Evidencia URL vÃ¡lida (https) y accesible**: +15
- **R3 Timestamp reciente (<= X horas)**: +15
- **R4 Campos mÃ­nimos completos**: +10
- **R5 CorroboraciÃ³n cruzada (si habilitada)**: +20

Umbrales sugeridos:
- **CONFIRMADO:** score â‰¥ 70
- **EN_VERIFICACION:** 40â€“69
- **NO_VERIFICADO:** < 40

---

### 3.3 Requisitos de interfaces externas

#### 3.3.1 Interfaces de usuario (UI)
- **UI-01:** Panel web responsive con:
  - Dashboard (Ãºltimas alertas)
  - GestiÃ³n de fuentes
  - Vista de scraping (estado/errores)
  - Reglas de verificaciÃ³n
  - Suscripciones (usuario)

#### 3.3.2 Interfaces de software (API)
- **API-01:** `GET /alerts?type=&zone=&from=&to=&status=`
- **API-02:** `GET /alerts/{id}`
- **API-03:** `POST /admin/sources` (admin)
- **API-04:** `POST /admin/sources/{id}/run` (admin/operador)
- **API-05:** `POST /subscriptions` (usuario)

#### 3.3.3 Interfaces de comunicaciones
- Uso de HTTPS para comunicaciones externas.
- Canales de notificaciÃ³n (Telegram/email/WhatsApp) vÃ­a APIs del proveedor.

---

### 3.4 Requisitos no funcionales (NFR)

#### 3.4.1 Rendimiento
- **NFR-01:** El sistema debe procesar un evento desde detecciÃ³n hasta publicaciÃ³n en â‰¤ 60 s (promedio) en ambiente de laboratorio.
- **NFR-02:** El sistema soportarÃ¡ al menos 1000 eventos almacenados y consultas concurrentes bÃ¡sicas (â‰¥ 20 usuarios).

#### 3.4.2 Disponibilidad y tolerancia a fallos
- **NFR-03:** Ante caÃ­da de una fuente, el sistema debe continuar operando con las restantes.
- **NFR-04:** Los scrapers deben reintentar con backoff hasta N veces antes de marcar error.

#### 3.4.3 Seguridad
- **NFR-05:** AutenticaciÃ³n con JWT (o sesiÃ³n segura) para panel.
- **NFR-06:** GestiÃ³n de secretos (tokens/credenciales) por variables de entorno o vault.
- **NFR-07:** Control de acceso por rol.
- **NFR-08:** SanitizaciÃ³n de entradas (evitar inyecciÃ³n en filtros y manejo seguro de archivos si hubiera uploads).

#### 3.4.4 Privacidad
- **NFR-09:** El sistema no almacenarÃ¡ datos sensibles personales; suscripciones solo guardarÃ¡n identificadores mÃ­nimos.

#### 3.4.5 Mantenibilidad
- **NFR-10:** Cada fuente tendrÃ¡ un scraper desacoplado con pruebas unitarias de parsing.
- **NFR-11:** DocumentaciÃ³n de configuraciÃ³n de scrapers y reglas.

#### 3.4.6 Portabilidad
- **NFR-12:** Despliegue mediante Docker Compose.
- **NFR-13:** Compatibilidad con Linux, Windows (WSL2), y macOS.

#### 3.4.7 Observabilidad
- **NFR-14:** Logs estructurados y mÃ©tricas exportables.
- **NFR-15:** Dashboard de monitoreo con Grafana.

#### 3.4.8 Costos
- **NFR-16:** Stack tecnolÃ³gico 100% gratuito y open-source.
- **NFR-17:** Uso de servicios gratuitos para notificaciones (Telegram Bot API, SMTP free tier).

---

### 3.5 Requisitos de calidad de datos
- **DQ-01:** Campos obligatorios no nulos en eventos normalizados.
- **DQ-02:** DeduplicaciÃ³n basada en (tipo + zona + occurred_at ventana + fuente).
- **DQ-03:** Registro de evidencia URL para eventos publicados.

---

## 4. Casos de uso (resumen)

### CU-01: Configurar fuente oficial (Admin)
- **Pre:** Admin autenticado.
- **Flujo:** Admin crea fuente â†’ define frecuencia y parser â†’ activa.
- **Post:** Fuente lista para scraping.

### CU-02: Ejecutar scraping y publicar alerta
- **Pre:** Fuente activa.
- **Flujo:** Scraper detecta evento â†’ normaliza â†’ verifica â†’ publica â†’ notifica.
- **Post:** Evento visible y notificado si CONFIRMADO.

### CU-03: Suscribirse a alertas (Usuario)
- **Pre:** Usuario registrado.
- **Flujo:** Usuario selecciona tipo/zona/canal â†’ guarda.
- **Post:** Recibe notificaciones futuras.

### CU-04: Revisar evento en verificaciÃ³n (Operador)
- **Pre:** Operador autenticado.
- **Flujo:** Filtra EN_VERIFICACION â†’ revisa evidencia â†’ (opcional) marca como CONFIRMADO/NO_VERIFICADO.
- **Post:** Se actualiza estado y auditorÃ­a.

---

## 5. Criterios de aceptaciÃ³n (por entregable)

### 5.1 MVP (Fase II)
- Scraping funcionando para 2 fuentes.
- NormalizaciÃ³n + deduplicaciÃ³n.
- Panel con listado/filtros.
- VerificaciÃ³n por reglas bÃ¡sicas + estados.

### 5.2 VersiÃ³n final (Fase III)
- 3 fuentes integradas.
- CorroboraciÃ³n cruzada (al menos para 1 tipo de evento).
- Notificaciones operativas (Telegram/email).
- Docker Compose + documentaciÃ³n + demo reproducible.

---

## 6. Matriz de trazabilidad (ejemplo)
| Requisito | Caso de uso | MÃ³dulo |
|---|---|---|
| RF-01 | CU-01 | Panel Admin / Sources |
| RF-04 | CU-02 | Scrapers |
| RF-11 | CU-02 | Verification Service |
| RF-20 | CU-02 | Notification Service |
| RF-19 | CU-03 | Subscriptions |

---

## 7. ApÃ©ndices

### 7.1 Riesgos y mitigaciones
- **Cambio de HTML en fuentes:** parsers con tests; alertas de parsing fallido; fallback.
- **Bloqueos por scraping agresivo:** rate limit, caching, frecuencia razonable.
- **Falsos positivos:** reglas explicables, umbrales ajustables, revisiÃ³n humana opcional.

### 7.2 Supuestos de despliegue (laboratorio)
- 1 VM o PC con Docker.
- Base de datos (PostgreSQL) en contenedor.
- Servicios en contenedores separados.

### 7.3 Glosario de severidad (sugerido)
- Baja / Media / Alta segÃºn fuente.

---

## 8. Stack Tecnológico (100% Free/Open-Source)

### 8.1 Resumen ejecutivo
El sistema utiliza un stack completamente **gratuito y open-source**, optimizado para entornos académicos con capacidad de escalar a producción.

### 8.2 Tecnologías por capa

| Capa | Tecnología | Versión | Licencia | Justificación |
|------|------------|---------|----------|---------------|
| **Backend** | Python | 3.11+ | PSF | Ecosistema superior para scraping |
| **Web Framework** | FastAPI | 0.109+ | MIT | Async, OpenAPI, alto rendimiento |
| **Scraping Estructurado** | Scrapy | 2.11+ | BSD | Framework completo para crawling |
| **Scraping Dinámico** | Playwright | 1.40+ | Apache 2.0 | Headless browser automation |
| **HTML Parsing** | BeautifulSoup4 | 4.12+ | MIT | Parsing simple estático |
| **Database** | PostgreSQL | 15+ | PostgreSQL | ACID, JSONB, event sourcing |
| **Cache** | Redis | 7+ | BSD | Pub/sub, rate limiting |
| **Message Broker** | RabbitMQ | 3.12+ | MPL 2.0 | AMQP, reliable messaging |
| **API Gateway** | Traefik | 3.0+ | MIT | Cloud-native, auto-discovery |
| **Frontend** | Vue.js | 3.3+ | MIT | Progressive framework |
| **UI Components** | Vuetify | 3.4+ | MIT | Material Design |
| **Build Tool** | Vite | 5.0+ | MIT | Fast dev server |
| **Containerization** | Docker | 24+ | Apache 2.0 | Containerización |
| **Orchestration** | Docker Compose | 2.23+ | Apache 2.0 | Multi-container apps |
| **Metrics** | Prometheus | 2.48+ | Apache 2.0 | Time-series metrics |
| **Dashboards** | Grafana | 10.2+ | AGPL 3.0 | Visualization |
| **Telegram** | python-telegram-bot | 20.7+ | LGPL 3.0 | Telegram Bot API |
| **Email** | aiosmtplib | 3.0+ | MIT | Async SMTP |

### 8.3 Librerías auxiliares Python
- **httpx 0.25+**: Cliente HTTP async
- **APScheduler 3.10+**: Programación de tareas
- **structlog 23.2+**: Logging estructurado
- **pydantic 2.5+**: Validación de datos
- **SQLAlchemy 2.0+**: ORM para PostgreSQL
- **alembic 1.13+**: Migraciones de base de datos

### 8.4 Servicios de notificación gratuitos
- **Telegram Bot API**: Ilimitado y gratuito
- **Gmail SMTP**: 500 emails/día (free tier)
- **Mailgun**: 5,000 emails/mes (free tier)
- **SendGrid**: 100 emails/día (free tier)

---

## 9. Arquitectura del Sistema

### 9.1 Patrón arquitectónico
**Event-Driven Microservices Architecture** con los siguientes patrones:
- Event-Driven Architecture (EDA)
- Event Sourcing
- CQRS (Command Query Responsibility Segregation)
- API Gateway Pattern
- Circuit Breaker Pattern

### 9.2 Componentes principales

#### Scraper Service
- **Responsabilidad**: Extracción de datos de fuentes oficiales
- **Tecnología**: Python + Scrapy/Playwright
- **Características**:
  - Scheduler con APScheduler
  - Rate limiting con Redis
  - Retry con exponential backoff
  - Almacena eventos crudos en PostgreSQL
  - Publica a RabbitMQ (raw_events queue)

#### Normalizer Service
- **Responsabilidad**: Transformación a esquema común
- **Tecnología**: Python + Pydantic
- **Características**:
  - Consume de raw_events queue
  - Valida campos obligatorios
  - Genera hash de deduplicación
  - Almacena eventos normalizados
  - Publica a normalized_events queue

#### Verifier Service
- **Responsabilidad**: Cálculo de confianza y estado
- **Tecnología**: Python
- **Características**:
  - Consume de normalized_events queue
  - Aplica reglas de scoring
  - Verifica lista blanca de dominios
  - Detecta duplicados
  - Actualiza estado
  - Publica eventos confirmados

#### Notifier Service
- **Responsabilidad**: Envío de notificaciones
- **Tecnología**: Python + python-telegram-bot + aiosmtplib
- **Características**:
  - Consume de confirmed_events queue
  - Lee suscripciones de PostgreSQL
  - Envía por múltiples canales
  - Registra estado de envío
  - Retry en caso de fallo

#### API Gateway
- **Responsabilidad**: API REST pública
- **Tecnología**: FastAPI
- **Endpoints principales**:
  - GET /api/alerts
  - GET /api/alerts/{id}
  - POST /api/subscriptions
  - POST /api/admin/sources

#### Admin Panel
- **Responsabilidad**: Interfaz de administración
- **Tecnología**: Vue.js 3 + Vuetify
- **Funcionalidades**:
  - Dashboard de alertas
  - Gestión de fuentes
  - Monitoreo de scrapers
  - Configuración de reglas

### 9.3 Flujo de datos event-driven

`
FASE 1: SCRAPING
Scraper ? PostgreSQL (raw_event)
Scraper ? RabbitMQ (raw_events queue)

FASE 2: NORMALIZACIÓN
RabbitMQ ? Normalizer
Normalizer ? PostgreSQL (event)
Normalizer ? RabbitMQ (normalized_events queue)

FASE 3: VERIFICACIÓN
RabbitMQ ? Verifier
Verifier ? PostgreSQL (update event.status, event.score)
IF status = CONFIRMADO:
   Verifier ? RabbitMQ (confirmed_events queue)

FASE 4: NOTIFICACIÓN
RabbitMQ ? Notifier
Notifier ? PostgreSQL (read subscriptions)
Notifier ? External APIs (Telegram, Email)
Notifier ? PostgreSQL (notification log)
`

### 9.4 Diagramas de arquitectura

Ver archivo complementario: rchitecture_overview.md para:
- Diagrama de contexto (C4 Level 1)
- Diagrama de contenedores (C4 Level 2)
- Diagrama de componentes (C4 Level 3)
- Flujo de datos detallado
- Arquitectura de despliegue Docker
- Modelo de datos ER

---

## 10. Estrategia de Despliegue

### 10.1 Entorno de laboratorio

#### Requisitos mínimos
- **CPU**: 4 cores
- **RAM**: 8 GB
- **Disco**: 50 GB SSD
- **OS**: Ubuntu 22.04 LTS / Windows 11 con WSL2 / macOS
- **Software**: Docker 24+, Docker Compose 2.23+, Git

#### Estructura de directorios
`
sistema_alertas/
+-- docker-compose.yml
+-- .env
+-- services/
¦   +-- scraper/
¦   +-- normalizer/
¦   +-- verifier/
¦   +-- notifier/
¦   +-- api-gateway/
¦   +-- admin-panel/
+-- config/
¦   +-- traefik/
¦   +-- prometheus/
¦   +-- grafana/
+-- data/
    +-- postgres/
    +-- redis/
    +-- rabbitmq/
`

### 10.2 Servicios Docker Compose

`yaml
services:
  traefik:       # Reverse proxy (puerto 80, 443)
  postgres:      # Base de datos (puerto 5432)
  redis:         # Cache (puerto 6379)
  rabbitmq:      # Message broker (puerto 5672, 15672)
  scraper:       # Scraper service
  normalizer:    # Normalizer service
  verifier:      # Verifier service
  notifier:      # Notifier service
  api-gateway:   # API REST
  admin-panel:   # Frontend Vue.js
  prometheus:    # Métricas (puerto 9090)
  grafana:       # Dashboards (puerto 3000)
`

### 10.3 Variables de entorno (.env)

`ash
# Database
DB_PASSWORD=secure_password_here

# RabbitMQ
RABBITMQ_PASSWORD=rabbitmq_password_here

# JWT
JWT_SECRET=your_jwt_secret_key_here

# Telegram (GRATIS)
TELEGRAM_BOT_TOKEN=your_telegram_bot_token

# Email SMTP (GRATIS - Gmail/Mailgun/SendGrid)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your_email@gmail.com
SMTP_PASSWORD=your_app_password

# Grafana
GRAFANA_PASSWORD=admin_password_here
`

### 10.4 Comandos de despliegue

`ash
# 1. Clonar repositorio
git clone <repo-url>
cd sistema_alertas

# 2. Configurar variables de entorno
cp .env.example .env
nano .env

# 3. Construir imágenes
docker-compose build

# 4. Iniciar servicios
docker-compose up -d

# 5. Verificar estado
docker-compose ps

# 6. Ver logs
docker-compose logs -f

# 7. Acceder a servicios
# - Admin Panel: http://localhost/admin
# - API: http://localhost/api
# - Grafana: http://localhost:3000
# - RabbitMQ: http://localhost:15672

# 8. Detener servicios
docker-compose down
`

---

## 11. Roadmap de Desarrollo

### Fase I - Fundamentos (Semanas 1-2)
**Objetivo**: Infraestructura base y primer scraper

- Configurar repositorio Git
- Crear estructura de directorios
- Configurar Docker Compose (PostgreSQL, Redis, RabbitMQ)
- Implementar modelo de datos
- Desarrollar primer scraper
- Crear API básica con FastAPI

**Entregable**: Scraper funcional que almacena eventos

### Fase II - Pipeline Completo (Semanas 3-4)
**Objetivo**: MVP con normalización, verificación y notificaciones

- Implementar Normalizer Service
- Implementar Verifier Service
- Desarrollar 2-3 scrapers
- Implementar Notifier Service (Telegram)
- Crear endpoints API completos
- Desarrollar Admin Panel (Vue.js)
- Configurar Traefik

**Entregable**: Sistema end-to-end con notificaciones

### Fase III - Producción (Semanas 5-6)
**Objetivo**: Sistema robusto con observabilidad

- Implementar corroboración cruzada
- Agregar notificaciones Email
- Configurar Prometheus + Grafana
- Implementar health checks
- Desarrollar tests
- Documentación completa
- Demo y presentación

**Entregable**: Sistema completo y documentado

---

## 12. Conclusiones

El Sistema de Alertas Comunitarias Verificadas (SACV) representa una solución completa, escalable y **100% gratuita** para la detección, verificación y notificación de eventos críticos. 

**Ventajas clave**:
- Stack tecnológico moderno y gratuito
- Arquitectura event-driven escalable
- Despliegue simplificado con Docker
- Observabilidad integrada
- Extensible y mantenible

**Próximos pasos**:
1. Aprobar stack tecnológico
2. Iniciar Fase I de desarrollo
3. Configurar entorno de laboratorio
4. Desarrollar primer scraper funcional

---

**Fin del documento - Versión 2.0 Completa**

**Documentos complementarios**:
- rchitecture_overview.md: Diagramas detallados de arquitectura
- implementation_plan.md: Plan de implementación técnico
